from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import MongoDBAtlasVectorSearch
from langchain_ollama.embeddings import OllamaEmbeddings
from pymongo import MongoClient
import gridfs
from dotenv import load_dotenv
import os

load_dotenv()

# MongoDB setup
client = MongoClient(os.getenv("MONGODB_URI"))
db = client["MySkiApp"]
fs = gridfs.GridFS(db)
collection = db["documents"]

# FiÈ™ierul PDF de procesat
filename = "Skiing tradition.pdf"
pdf_path = os.path.join(os.path.dirname(__file__), "docs", filename)

# VerificÄƒ dacÄƒ fiÈ™ierul este deja salvat Ã®n GridFS
existing_file = fs.find_one({"filename": filename})
if existing_file:
    file_id = existing_file._id
    print(f"ðŸ“„ FiÈ™ierul '{filename}' deja existÄƒ Ã®n GridFS cu ID: {file_id}")
else:
    with open(pdf_path, "rb") as f:
        file_id = fs.put(f, filename=filename)
        print(f"âœ… PDF salvat Ã®n MongoDB cu ID: {file_id}")

# Extrage conÈ›inutul text din PDF
loader = PyPDFLoader(pdf_path)
docs = loader.load()

# AtaÈ™eazÄƒ metadate: nume fiÈ™ier È™i ID GridFS
for doc in docs:
    doc.metadata["file_id"] = str(file_id)
    doc.metadata["filename"] = filename

# Split Ã®n bucÄƒÈ›i
splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
chunks = splitter.split_documents(docs)

# Embedding
embeddings = OllamaEmbeddings(model="nomic-embed-text")

# Indexare Ã®n MongoDB Atlas Vector Search
vectorstore = MongoDBAtlasVectorSearch.from_documents(
    documents=chunks,
    embedding=embeddings,
    collection=collection,
    index_name="default"
)

print(f"âœ… {len(chunks)} bucÄƒÈ›i de text au fost indexate È™i legate corect de fiÈ™ierul '{filename}'.")
